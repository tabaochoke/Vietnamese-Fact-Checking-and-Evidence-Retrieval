{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6673769,"sourceType":"datasetVersion","datasetId":3850405},{"sourceId":6715913,"sourceType":"datasetVersion","datasetId":3869703},{"sourceId":6741139,"sourceType":"datasetVersion","datasetId":3882041},{"sourceId":6779746,"sourceType":"datasetVersion","datasetId":3901433},{"sourceId":6860211,"sourceType":"datasetVersion","datasetId":3942709},{"sourceId":6860236,"sourceType":"datasetVersion","datasetId":3942721},{"sourceId":6860252,"sourceType":"datasetVersion","datasetId":3942727},{"sourceId":6860271,"sourceType":"datasetVersion","datasetId":3942731},{"sourceId":6860279,"sourceType":"datasetVersion","datasetId":3942733},{"sourceId":6881841,"sourceType":"datasetVersion","datasetId":3953937}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install --quiet pyvi\n!pip install --quiet evaluate\n!pip install -U sentence-transformers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --quiet underthesea","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModel, AutoTokenizer , TrainingArguments, Trainer , AutoModelForQuestionAnswering , AdamW , get_scheduler , DataCollatorWithPadding\nfrom datasets import load_dataset , concatenate_datasets\n#from accelerate import Accelerator\nfrom pyvi import ViTokenizer, ViPosTagger\nimport evaluate\nfrom torch.utils.data import DataLoader\nfrom accelerate import Accelerator\n#from transformers import DataCollatorWithPadding\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit , train_test_split\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom datasets import Dataset,DatasetDict\nimport collections\nimport evaluate\nfrom huggingface_hub import notebook_login\n# from underthesea import sent_tokenize ,  text_normalize , word_tokenize\nimport sentence_transformers\nfrom sentence_transformers import SentenceTransformer, util\nimport re\nimport torch.nn as nn\nimport pandas as pd\nimport seaborn as sns\nfrom underthesea import word_tokenize\nSEED = 1337","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\ncheckpoint = \"vinai/phobert-base-v2\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LOAD PREPROCESS DATA AND PRETRAINED MODEL","metadata":{}},{"cell_type":"code","source":"# data = load_dataset(\"json\", data_files=\"/kaggle/input/ranking-4-uit/FULL_27K_TRAINING_RANKING_DATA_RANKING_4\")\n# data = concatenate_datasets([data0['train'], data5['train'], data10['train'], data15['train'], data20])\ndata = load_dataset(\"json\", data_files=\"/kaggle/input/uit-final-ranking-data-top6/FULL_27K_TRAINING_RANKING_DATA_RANKING_4 (3)\")\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def segment_context (samples) :\n    return {\"new_context\" : [word_tokenize(sample, format=\"text\") for sample in samples[\"new_context\"] ] }","metadata":{"execution":{"iopub.status.busy":"2023-11-05T01:19:22.740737Z","iopub.execute_input":"2023-11-05T01:19:22.741035Z","iopub.status.idle":"2023-11-05T01:19:22.745744Z","shell.execute_reply.started":"2023-11-05T01:19:22.740994Z","shell.execute_reply":"2023-11-05T01:19:22.744772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_segment = data.map (segment_context , batched = True)\ndata_segment","metadata":{"execution":{"iopub.status.busy":"2023-11-05T01:19:26.100735Z","iopub.execute_input":"2023-11-05T01:19:26.101112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_segment = data_segment[\"train\"]","metadata":{"execution":{"iopub.status.busy":"2023-11-04T13:36:21.106765Z","iopub.execute_input":"2023-11-04T13:36:21.107501Z","iopub.status.idle":"2023-11-04T13:36:21.112149Z","shell.execute_reply.started":"2023-11-04T13:36:21.107465Z","shell.execute_reply":"2023-11-04T13:36:21.111043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cls_tok = tokenizer.special_tokens_map['cls_token']\nsep_tok = tokenizer.special_tokens_map['sep_token']\ndef fix_input (sample) :\n    return {\"input\" : cls_tok + ' ' + sample['claim'] + ' ' + sep_tok +  ' ' +sample['new_context'] + ' ' + sep_tok  }","metadata":{"execution":{"iopub.status.busy":"2023-11-04T13:36:23.025145Z","iopub.execute_input":"2023-11-04T13:36:23.025862Z","iopub.status.idle":"2023-11-04T13:36:23.031231Z","shell.execute_reply.started":"2023-11-04T13:36:23.025834Z","shell.execute_reply":"2023-11-04T13:36:23.030054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_fix_input = data_segment.map (fix_input )","metadata":{"execution":{"iopub.status.busy":"2023-11-04T13:36:46.566498Z","iopub.execute_input":"2023-11-04T13:36:46.567400Z","iopub.status.idle":"2023-11-04T13:36:54.313368Z","shell.execute_reply.started":"2023-11-04T13:36:46.567368Z","shell.execute_reply":"2023-11-04T13:36:54.312449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize (sample) :\n    return tokenizer(sample [\"input\"] , truncation= True , max_length = 256)\ndata_tokenize = data_fix_input.map (tokenize , batched = True )","metadata":{"execution":{"iopub.status.busy":"2023-11-04T13:36:54.315441Z","iopub.execute_input":"2023-11-04T13:36:54.316195Z","iopub.status.idle":"2023-11-04T13:37:46.445039Z","shell.execute_reply.started":"2023-11-04T13:36:54.316154Z","shell.execute_reply":"2023-11-04T13:37:46.443793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_tokenize","metadata":{"execution":{"iopub.status.busy":"2023-11-04T13:37:46.446373Z","iopub.execute_input":"2023-11-04T13:37:46.446674Z","iopub.status.idle":"2023-11-04T13:37:46.453905Z","shell.execute_reply.started":"2023-11-04T13:37:46.446649Z","shell.execute_reply":"2023-11-04T13:37:46.453064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a = []\n# for i in range (len ( data_)) :\n#      a.append ( len ( data_[i]['input_ids'] )) \n# a = np.array (a)\n# sns.histplot (a)\n# print (max(a))","metadata":{"execution":{"iopub.status.busy":"2023-11-04T13:33:30.912866Z","iopub.status.idle":"2023-11-04T13:33:30.913321Z","shell.execute_reply.started":"2023-11-04T13:33:30.913094Z","shell.execute_reply":"2023-11-04T13:33:30.913115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = data_tokenize.remove_columns (['context', 'claim', 'verdict', 'evidence', 'domain', '__index_level_0__', 'new_context','input'])\ntrain_data","metadata":{"execution":{"iopub.status.busy":"2023-11-04T13:39:29.908523Z","iopub.execute_input":"2023-11-04T13:39:29.909225Z","iopub.status.idle":"2023-11-04T13:39:29.918640Z","shell.execute_reply.started":"2023-11-04T13:39:29.909193Z","shell.execute_reply":"2023-11-04T13:39:29.917802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_dataset = train_data.train_test_split (train_size = 0.8)\nsplit_dataset","metadata":{"execution":{"iopub.status.busy":"2023-11-04T13:39:37.356845Z","iopub.execute_input":"2023-11-04T13:39:37.357510Z","iopub.status.idle":"2023-11-04T13:39:37.387236Z","shell.execute_reply.started":"2023-11-04T13:39:37.357478Z","shell.execute_reply":"2023-11-04T13:39:37.386370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classification model","metadata":{}},{"cell_type":"code","source":"class CustomPhoBert(nn.Module):\n    def __init__(self, n_classes):\n        super(CustomPhoBert, self).__init__()\n        self.model = AutoModel.from_pretrained(checkpoint , num_labels = 3)\n        self.tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n#         self.drop = nn.Dropout(p=0.2)\n#         self.fc = nn.Linear(self.bert.config.hidden_size, n_classes)\n#         nn.init.normal_(self.fc.weight, std=0.02)\n#         nn.init.normal_(self.fc.bias, 0)\n        self.att = nn.Sequential(\n                            nn.Linear(768 , 384),\n                            nn.Tanh(),\n                            nn.Linear ( 384 , 1),\n                            nn.Softmax(dim=1)\n                            )\n        self.drop = nn.Dropout (0.2)\n        self.fc = nn.Linear (768 , 3)\n        self.mini_linear = nn.Linear (3 , 1)\n        self._init_weights(self.att)\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n            \n    def forward(self, **batch):\n        \n        \n        a = self.model (**batch )\n    #     last_hidden_state , pooler = a.last_hidden_state , a.pooler_output # x , 100 , 768 # x , 758  # batch ,tok_len , hiddensize\n        last_hidden_state = a.last_hidden_state\n        weights = self.att (last_hidden_state)   # bacth ,tok_len , 1\n        feature = torch.sum(weights * last_hidden_state, dim=1) # batch , tok_len, hidden_size --> batch , hiddensize )\n        drop_feature = self.drop (feature)\n        output = self.fc(drop_feature) #   batch , label\n\n#         q1 = torch.mean ( output[start_indices [0]: end_indices[0]] , dim =0 ).view (1,3) # minisize , label # 2,3\n#         q2 = torch.mean ( output[start_indices [1]: end_indices[1]] , dim =0 ).view (1,3)\n#         q3 = torch.mean ( output[start_indices[2]: end_indices[2]] , dim =0 ).view (1,3)\n#         q4 = torch.mean ( output[start_indices[3]: end_indices[3]] , dim =0 ).view (1,3) \n#         logits = torch.concat ((q1,q2,q3,q4) ,0)\n        \n#        return logits\n        return output\nmodel = CustomPhoBert (3).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T13:39:41.053964Z","iopub.execute_input":"2023-11-04T13:39:41.054865Z","iopub.status.idle":"2023-11-04T13:40:03.236889Z","shell.execute_reply.started":"2023-11-04T13:39:41.054816Z","shell.execute_reply":"2023-11-04T13:40:03.235868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\n# device = torch.device (\"cuda\") if torch.cuda.is_available() else torch.device (\"cpu\" )\n# model.to(device)\n#Dataloader\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\ntrain_dataloader = DataLoader (split_dataset[\"train\"], batch_size= 32, shuffle=True , collate_fn = data_collator  )\nval_dataloader = DataLoader (split_dataset[\"test\"], batch_size= 64, shuffle=True , collate_fn = data_collator )\n# test_dataloader = DataLoader (split_dataset[\"test\"] , batch_size=16, shuffle=True , collate_fn = data_collator )\nstep_to_train = epochs * len (train_dataloader)\noptimizer = torch.optim.AdamW (model.parameters () , lr = 3e-5)\nscheduler = get_scheduler (name = \"cosine\" , \n                           optimizer = optimizer ,\n                           num_warmup_steps=0,\n                           num_training_steps = step_to_train\n                          )\n#accelerator\naccelerator = Accelerator ()\ntrain_dataloader ,val_dataloader ,model , optimizer= accelerator.prepare (train_dataloader  , val_dataloader , model , optimizer)\n\n#optimzier and scheduler\n#Metric\nmetric_train_acc = evaluate.load(\"accuracy\")\nmetric_valid_acc = evaluate.load(\"accuracy\")\nmetric_train_f1 = evaluate.load(\"f1\")\nmetric_valid_f1 = evaluate.load(\"f1\")","metadata":{"execution":{"iopub.status.busy":"2023-11-04T13:40:03.238642Z","iopub.execute_input":"2023-11-04T13:40:03.238947Z","iopub.status.idle":"2023-11-04T13:40:09.612540Z","shell.execute_reply.started":"2023-11-04T13:40:03.238921Z","shell.execute_reply":"2023-11-04T13:40:09.611754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LOAD FINETUNE MODEL IF YOU HAVE ONE","metadata":{}},{"cell_type":"code","source":"# model.load_state_dict(torch.load(\"/kaggle/input/viedeberta-small-model-ranking-10000/viedeberta_small_model_ranking\"))","metadata":{"execution":{"iopub.status.busy":"2023-11-02T05:34:01.559151Z","iopub.execute_input":"2023-11-02T05:34:01.559904Z","iopub.status.idle":"2023-11-02T05:34:01.563920Z","shell.execute_reply.started":"2023-11-02T05:34:01.559841Z","shell.execute_reply":"2023-11-02T05:34:01.563085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import gc\n# torch.cuda.empty_cache()\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-11-02T05:34:01.565392Z","iopub.execute_input":"2023-11-02T05:34:01.565817Z","iopub.status.idle":"2023-11-02T05:34:01.913484Z","shell.execute_reply.started":"2023-11-02T05:34:01.565782Z","shell.execute_reply":"2023-11-02T05:34:01.912323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nbest_val_acc = 0\ni=0\nfor epoch in range (epochs) :\n    model.train ()\n    losses = []\n    for batch in tqdm ( train_dataloader )  :\n        labels = batch.pop (\"labels\")\n        \n        logits = model(**batch)\n\n        criterion = nn.CrossEntropyLoss()\n        #print (outputs.shape , labels.shape)\n        loss = criterion(logits,labels)\n\n        accelerator.backward (loss)\n\n        optimizer.step ()\n        scheduler.step ()\n        optimizer.zero_grad ()\n\n        losses.append (loss.item())\n        predict = torch.argmax (logits, dim = -1)\n        #print ( predict.shape)\n        metric_train_acc.add_batch (references=labels, predictions = predict)\n        metric_train_f1.add_batch (references=labels, predictions = predict)\n    print (\"Epoch : {} , Loss : {} , Accuracy : {} , F1 : {}\".format (epoch + 1 , np.mean( losses) , metric_train_acc.compute ()['accuracy'] , metric_train_f1.compute(average=\"weighted\")['f1'] ) )\n    \n    model.eval()\n    val_losses = []\n    for batch in tqdm ( val_dataloader ) :\n        with torch.no_grad () :\n            labels = batch.pop (\"labels\")\n            logits = model.forward (**batch)\n            \n            criterion = nn.CrossEntropyLoss()\n            #print (outputs.shape , labels.shape)\n            loss = criterion(logits,labels)\n            val_losses.append (loss.item())\n        \n            predict = torch.argmax (logits, dim = -1)\n            metric_valid_acc.add_batch (references=labels, predictions = predict)\n            metric_valid_f1.add_batch (references=labels, predictions = predict )\n            \n    val_acc = metric_valid_acc.compute ()['accuracy']\n    if val_acc > best_val_acc :\n        torch.save(model.state_dict(), \"Phobert_v2_best_model_full_data_{}\".format (i))\n        best_val_acc = val_acc\n        i+=1\n    print (\"Epoch : {}, Val Loss: {} , Validation  ACC Result : {} , Validation F1 Result :{}\".format (epoch + 1, np.mean( val_losses) , val_acc , metric_valid_f1.compute (average=\"weighted\")['f1'] ))","metadata":{"execution":{"iopub.status.busy":"2023-11-04T13:40:09.613708Z","iopub.execute_input":"2023-11-04T13:40:09.614022Z","iopub.status.idle":"2023-11-04T15:53:32.451848Z","shell.execute_reply.started":"2023-11-04T13:40:09.613975Z","shell.execute_reply":"2023-11-04T15:53:32.450821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_pd = data.to_json(\"data\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}